<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Gemini Model Interaction</title>
    <style>
        body, html {
            margin: 0;
            padding: 0;
            height: 100%;
            font-family: Arial, sans-serif;
            overflow: hidden;
        }
        .container {
            display: grid;
            grid-template-columns: 1fr 1fr;
            grid-template-rows: auto 1fr auto;
            height: 100vh;
            background-color: #f0f0f0;
        }
        h1 {
            grid-column: 1 / -1;
            text-align: center;
            background-color: #4CAF50;
            color: white;
            margin: 0;
            padding: 20px;
        }
        #camera-container {
            grid-column: 1;
            grid-row: 2;
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            padding: 20px;
        }
        #video {
            width: 100%;
            max-height: 60vh;
            border-radius: 8px;
        }
        #response-container {
            grid-column: 2;
            grid-row: 2;
            background-color: white;
            padding: 20px;
            overflow-y: auto;
        }
        #response-text {
            white-space: pre-wrap;
        }
        .input-area {
            grid-column: 1 / -1;
            grid-row: 3;
            display: flex;
            padding: 20px;
            background-color: #e0e0e0;
        }
        #user-input {
            flex-grow: 1;
            padding: 10px;
            margin-right: 10px;
            border: 1px solid #ddd;
            border-radius: 4px;
        }
        button {
            background-color: #4CAF50;
            border: none;
            color: white;
            padding: 10px 20px;
            text-align: center;
            text-decoration: none;
            font-size: 16px;
            cursor: pointer;
            border-radius: 4px;
            margin-left: 5px;
        }
        #animation-container {
            position: absolute;
            bottom: 20px;
            left: 50%;
            transform: translateX(-50%);
            display: none;
        }
        .circle {
            width: 10px;
            height: 10px;
            border-radius: 50%;
            background-color: #4CAF50;
            margin: 0 5px;
            animation: bounce 0.5s ease infinite alternate;
        }
        .circle:nth-child(2) {
            animation-delay: 0.1s;
        }
        .circle:nth-child(3) {
            animation-delay: 0.2s;
        }
        .circle:nth-child(4) {
            animation-delay: 0.3s;
        }
        @keyframes bounce {
            to {
                transform: translateY(-10px);
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>Gemini Model Interaction</h1>
        
        <div id="camera-container">
            <video id="video" autoplay playsinline></video>
            <canvas id="canvas" style="display:none;"></canvas>
            <button id="capture-btn">Capture Image</button>
        </div>
        <div id="animation-container">
            <div class="circle"></div>
            <div class="circle"></div>
            <div class="circle"></div>
            <div class="circle"></div>
        </div>
        
        <div id="response-container">
            <h2>Response from Gemini:</h2>
            <p id="response-text"></p>
            
        </div>
        
        <div class="input-area">
            <input type="text" id="user-input" placeholder="Enter your input for the model">
            <button id="generate-btn">Generate</button>
            <button id="voice-btn">Voice Input</button>
        </div>
    </div>

    

    <script type="module">
        import { GoogleGenerativeAI } from "https://esm.run/@google/generative-ai";

        const API_KEY = "AIzaSyB2Ap-o973pkpyvPaKiktbZwd4LX1FxU2c";
        const context = "Act as a virtual assistant, user will give a live image of him and he ask questions you have to answer that questions on the basis of live image. here is the user question:-";
        const genAI = new GoogleGenerativeAI(API_KEY);

        const video = document.getElementById('video');
        const canvas = document.getElementById('canvas');
        const captureBtn = document.getElementById('capture-btn');
        const userInput = document.getElementById('user-input');
        const generateBtn = document.getElementById('generate-btn');
        const responseText = document.getElementById('response-text');
        const voiceBtn = document.getElementById('voice-btn');

        let imageData = null;

        async function startCamera() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ video: true });
                video.srcObject = stream;
            } catch (err) {
                console.error("Error accessing the camera:", err);
                alert("Error accessing the camera. Please make sure you've granted permission.");
            }
        }

        startCamera();

        captureBtn.addEventListener('click', captureImage);
        generateBtn.addEventListener('click', triggerGenerateResponse);
        voiceBtn.addEventListener('click', startVoiceRecognition);

        function captureImage() {
            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;
            canvas.getContext('2d').drawImage(video, 0, 0);
            imageData = canvas.toDataURL('image/jpeg').split(',')[1];
        }

        function triggerGenerateResponse() {
            if (!imageData || !userInput.value) {
                alert('Please capture an image and enter input for the model.');
                return;
            }

            responseText.textContent = 'Processing...';

            sendMessage(userInput.value, imageData)
                .catch(error => {
                    console.error('Error generating response:', error);
                    responseText.textContent = 'Error generating response. Please check console for details.';
                });
        }

        async function sendMessage(prompt, imageData) {
            try {
                const model = genAI.getGenerativeModel({ model: "gemini-1.5-pro" });

                const imageParts = [
                    {
                        inlineData: {
                            data: imageData,
                            mimeType: "image/jpeg"
                        }
                    }
                ];
                const final_prompt = context + prompt;
                const result = await model.generateContent([final_prompt, ...imageParts]);
                const response = await result.response;
                const text = response.text();
                responseText.textContent = text;
                console.log('Response generated successfully:', text);
                
                speakResponse(text);
            } catch (error) {
                console.error('Error in sendMessage:', error);
                throw error;
            }
        }

        function speakResponse(text) {
            const animationContainer = document.getElementById('animation-container');
            
            if ('speechSynthesis' in window) {
                const utterance = new SpeechSynthesisUtterance(text);
                
                utterance.onstart = () => {
                    animationContainer.style.display = 'flex';
                };
                
                utterance.onend = () => {
                    animationContainer.style.display = 'none';
                };
                
                speechSynthesis.speak(utterance);
            } else {
                console.warn('Text-to-speech not supported in this browser');
            }
        }

        function startVoiceRecognition() {
            if (!('webkitSpeechRecognition' in window)) {
                alert('Voice recognition not supported in this browser. Please use Google Chrome.');
                return;
            }

            const recognition = new webkitSpeechRecognition();
            recognition.continuous = false;
            recognition.interimResults = false;
            recognition.lang = 'en-US';

            recognition.onstart = () => {
                console.log('Voice recognition started...');
            };

            recognition.onresult = (event) => {
                const transcript = event.results[0][0].transcript;
                userInput.value = transcript;
                console.log('Voice input received:', transcript);
            };

            recognition.onerror = (event) => {
                console.error('Voice recognition error:', event.error);
                alert('Voice recognition error. Please try again.');
            };

            recognition.onend = () => {
                console.log('Voice recognition ended.');
                captureImage();
                triggerGenerateResponse();
            };

            recognition.start();
        }

        userInput.addEventListener('keydown', (event) => {
            if (event.key === 'Enter') {
                voiceBtn.click();
            }
        });
    </script>
</body>
</html>
